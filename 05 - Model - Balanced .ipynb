{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7578c91e-b642-41cf-ad4b-edf1eb3a8071",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f0307205-bcfb-4c02-af08-21777797ca8c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the split datasets\n",
    "df= pd.read_csv('Premier_League_Season_With_Team_IDs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2af3f81b-d2d6-46b1-b2d3-b98fd8dd91ea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f871d21f-f2bf-4396-b8cf-9dd10e095756",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Season</th>\n",
       "      <th>HomeTeam</th>\n",
       "      <th>AwayTeam</th>\n",
       "      <th>FTHG</th>\n",
       "      <th>FTAG</th>\n",
       "      <th>FTR</th>\n",
       "      <th>HTHG</th>\n",
       "      <th>HTAG</th>\n",
       "      <th>HTR</th>\n",
       "      <th>Referee</th>\n",
       "      <th>...</th>\n",
       "      <th>WHA</th>\n",
       "      <th>PSCH</th>\n",
       "      <th>PSCD</th>\n",
       "      <th>PSCA</th>\n",
       "      <th>GoalDiff_HT</th>\n",
       "      <th>GoalDiff_FT</th>\n",
       "      <th>TotalHomeShots</th>\n",
       "      <th>TotalAwayShots</th>\n",
       "      <th>HomeTeam_ID</th>\n",
       "      <th>AwayTeam_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015</td>\n",
       "      <td>Bournemouth</td>\n",
       "      <td>Aston Villa</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>D</td>\n",
       "      <td>M Clattenburg</td>\n",
       "      <td>...</td>\n",
       "      <td>4.00</td>\n",
       "      <td>1.82</td>\n",
       "      <td>3.88</td>\n",
       "      <td>4.70</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015</td>\n",
       "      <td>Chelsea</td>\n",
       "      <td>Swansea</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>D</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>H</td>\n",
       "      <td>M Oliver</td>\n",
       "      <td>...</td>\n",
       "      <td>10.00</td>\n",
       "      <td>1.37</td>\n",
       "      <td>5.04</td>\n",
       "      <td>10.88</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015</td>\n",
       "      <td>Everton</td>\n",
       "      <td>Watford</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>D</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>M Jones</td>\n",
       "      <td>...</td>\n",
       "      <td>5.00</td>\n",
       "      <td>1.75</td>\n",
       "      <td>3.76</td>\n",
       "      <td>5.44</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015</td>\n",
       "      <td>Leicester</td>\n",
       "      <td>Sunderland</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>H</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>H</td>\n",
       "      <td>L Mason</td>\n",
       "      <td>...</td>\n",
       "      <td>2.70</td>\n",
       "      <td>1.79</td>\n",
       "      <td>3.74</td>\n",
       "      <td>5.10</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>27</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015</td>\n",
       "      <td>Man United</td>\n",
       "      <td>Tottenham</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>H</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>H</td>\n",
       "      <td>J Moss</td>\n",
       "      <td>...</td>\n",
       "      <td>6.00</td>\n",
       "      <td>1.64</td>\n",
       "      <td>4.07</td>\n",
       "      <td>6.04</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3425</th>\n",
       "      <td>2024</td>\n",
       "      <td>Nott'm Forest</td>\n",
       "      <td>Bournemouth</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>D</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>H</td>\n",
       "      <td>M Oliver</td>\n",
       "      <td>...</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.24</td>\n",
       "      <td>3.50</td>\n",
       "      <td>3.37</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>17</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3426</th>\n",
       "      <td>2024</td>\n",
       "      <td>West Ham</td>\n",
       "      <td>Aston Villa</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>D</td>\n",
       "      <td>T Harrington</td>\n",
       "      <td>...</td>\n",
       "      <td>2.75</td>\n",
       "      <td>2.54</td>\n",
       "      <td>3.51</td>\n",
       "      <td>2.86</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>17</td>\n",
       "      <td>18</td>\n",
       "      <td>16</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3427</th>\n",
       "      <td>2024</td>\n",
       "      <td>Brentford</td>\n",
       "      <td>Crystal Palace</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>H</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>H</td>\n",
       "      <td>S Barrott</td>\n",
       "      <td>...</td>\n",
       "      <td>2.88</td>\n",
       "      <td>2.92</td>\n",
       "      <td>3.24</td>\n",
       "      <td>2.66</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>20</td>\n",
       "      <td>30</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3428</th>\n",
       "      <td>2024</td>\n",
       "      <td>Chelsea</td>\n",
       "      <td>Man City</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>A Taylor</td>\n",
       "      <td>...</td>\n",
       "      <td>1.83</td>\n",
       "      <td>3.86</td>\n",
       "      <td>3.91</td>\n",
       "      <td>1.97</td>\n",
       "      <td>-1</td>\n",
       "      <td>-2</td>\n",
       "      <td>13</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3429</th>\n",
       "      <td>2024</td>\n",
       "      <td>Leicester</td>\n",
       "      <td>Tottenham</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>D</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>C Kavanagh</td>\n",
       "      <td>...</td>\n",
       "      <td>1.65</td>\n",
       "      <td>4.64</td>\n",
       "      <td>4.33</td>\n",
       "      <td>1.71</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>22</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3430 rows Ã— 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Season       HomeTeam        AwayTeam  FTHG  FTAG FTR  HTHG  HTAG HTR  \\\n",
       "0       2015    Bournemouth     Aston Villa     0     1   A     0     0   D   \n",
       "1       2015        Chelsea         Swansea     2     2   D     2     1   H   \n",
       "2       2015        Everton         Watford     2     2   D     0     1   A   \n",
       "3       2015      Leicester      Sunderland     4     2   H     3     0   H   \n",
       "4       2015     Man United       Tottenham     1     0   H     1     0   H   \n",
       "...      ...            ...             ...   ...   ...  ..   ...   ...  ..   \n",
       "3425    2024  Nott'm Forest     Bournemouth     1     1   D     1     0   H   \n",
       "3426    2024       West Ham     Aston Villa     1     2   A     1     1   D   \n",
       "3427    2024      Brentford  Crystal Palace     2     1   H     1     0   H   \n",
       "3428    2024        Chelsea        Man City     0     2   A     0     1   A   \n",
       "3429    2024      Leicester       Tottenham     1     1   D     0     1   A   \n",
       "\n",
       "            Referee  ...    WHA  PSCH  PSCD   PSCA  GoalDiff_HT  GoalDiff_FT  \\\n",
       "0     M Clattenburg  ...   4.00  1.82  3.88   4.70            0           -1   \n",
       "1          M Oliver  ...  10.00  1.37  5.04  10.88            1            0   \n",
       "2           M Jones  ...   5.00  1.75  3.76   5.44           -1            0   \n",
       "3           L Mason  ...   2.70  1.79  3.74   5.10            3            2   \n",
       "4            J Moss  ...   6.00  1.64  4.07   6.04            1            1   \n",
       "...             ...  ...    ...   ...   ...    ...          ...          ...   \n",
       "3425       M Oliver  ...   2.80  2.24  3.50   3.37            1            0   \n",
       "3426   T Harrington  ...   2.75  2.54  3.51   2.86            0           -1   \n",
       "3427      S Barrott  ...   2.88  2.92  3.24   2.66            1            1   \n",
       "3428       A Taylor  ...   1.83  3.86  3.91   1.97           -1           -2   \n",
       "3429     C Kavanagh  ...   1.65  4.64  4.33   1.71           -1            0   \n",
       "\n",
       "      TotalHomeShots  TotalAwayShots  HomeTeam_ID  AwayTeam_ID  \n",
       "0                 13              10            0           10  \n",
       "1                 14              28            1           13  \n",
       "2                 15              16            2           15  \n",
       "3                 27              15            3           12  \n",
       "4                 10              13            4           14  \n",
       "...              ...             ...          ...          ...  \n",
       "3425              22              17           31            0  \n",
       "3426              17              18           16           10  \n",
       "3427              14              20           30           17  \n",
       "3428              13              16            1           18  \n",
       "3429              10              22            3           14  \n",
       "\n",
       "[3430 rows x 40 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8f8b31aa-a15b-4084-81f1-208561839662",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Season', 'HomeTeam', 'AwayTeam', 'FTHG', 'FTAG', 'FTR', 'HTHG', 'HTAG',\n",
      "       'HTR', 'Referee', 'HS', 'AS', 'HST', 'AST', 'HF', 'AF', 'HC', 'AC',\n",
      "       'HY', 'AY', 'HR', 'AR', 'B365H', 'B365D', 'B365A', 'PSH', 'PSD', 'PSA',\n",
      "       'WHH', 'WHD', 'WHA', 'PSCH', 'PSCD', 'PSCA', 'GoalDiff_HT',\n",
      "       'GoalDiff_FT', 'TotalHomeShots', 'TotalAwayShots', 'HomeTeam_ID',\n",
      "       'AwayTeam_ID'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a78a09-88a5-46b7-8923-22c368bbe8ea",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Based Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "96985880-9652-4533-b01f-2053785fcfcd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\GG\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Logistic Regression Results:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.59      0.59        64\n",
      "           1       0.34      0.41      0.37        49\n",
      "           2       0.78      0.70      0.74        89\n",
      "\n",
      "    accuracy                           0.59       202\n",
      "   macro avg       0.57      0.57      0.57       202\n",
      "weighted avg       0.61      0.59      0.60       202\n",
      "\n",
      "\n",
      "Random Forest Results:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.66      0.60        64\n",
      "           1       0.29      0.18      0.23        49\n",
      "           2       0.66      0.71      0.68        89\n",
      "\n",
      "    accuracy                           0.56       202\n",
      "   macro avg       0.50      0.52      0.50       202\n",
      "weighted avg       0.54      0.56      0.55       202\n",
      "\n",
      "\n",
      "XGBoost Results:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.61      0.58        64\n",
      "           1       0.31      0.22      0.26        49\n",
      "           2       0.70      0.75      0.72        89\n",
      "\n",
      "    accuracy                           0.58       202\n",
      "   macro avg       0.52      0.53      0.52       202\n",
      "weighted avg       0.56      0.58      0.57       202\n",
      "\n",
      "\n",
      "SVM Results:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.61      0.59        64\n",
      "           1       0.30      0.35      0.32        49\n",
      "           2       0.69      0.60      0.64        89\n",
      "\n",
      "    accuracy                           0.54       202\n",
      "   macro avg       0.52      0.52      0.52       202\n",
      "weighted avg       0.56      0.54      0.55       202\n",
      "\n",
      "\n",
      "Neural Network (MLP) Results:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.61      0.57        64\n",
      "           1       0.37      0.39      0.38        49\n",
      "           2       0.72      0.64      0.68        89\n",
      "\n",
      "    accuracy                           0.57       202\n",
      "   macro avg       0.55      0.55      0.54       202\n",
      "weighted avg       0.58      0.57      0.57       202\n",
      "\n",
      "\n",
      "KNN Results:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.59      0.55        64\n",
      "           1       0.23      0.33      0.27        49\n",
      "           2       0.71      0.46      0.56        89\n",
      "\n",
      "    accuracy                           0.47       202\n",
      "   macro avg       0.48      0.46      0.46       202\n",
      "weighted avg       0.53      0.47      0.49       202\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Feature selection (using match stats, removing betting odds)\n",
    "features = ['HS', 'AS', 'HST', 'AST', 'HF', 'AF', 'HC', 'AC', 'HY', 'AY', 'HR', 'AR']\n",
    "X = df[features]\n",
    "y = df['FTR']  # Target: Full-time result (Home win 'H', Draw 'D', Away win 'A')\n",
    "\n",
    "# Encode the target variable (convert 'H', 'D', 'A' to 0, 1, 2)\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "# Split the data by season (using Season column for the split)\n",
    "train_df = df[df['Season'] != 2024]  # All seasons except 2024 for training\n",
    "test_df = df[df['Season'] == 2024]   # Only 2024 season for testing\n",
    "\n",
    "# Features and target for training and testing\n",
    "X_train = train_df[features]\n",
    "y_train = label_encoder.fit_transform(train_df['FTR'])\n",
    "X_test = test_df[features]\n",
    "y_test = label_encoder.transform(test_df['FTR'])\n",
    "\n",
    "# Feature scaling\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Handling class imbalance using SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_balanced, y_train_balanced = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Initialize dictionary to store models and results\n",
    "models = {}\n",
    "results = {}\n",
    "\n",
    "# 1. Logistic Regression\n",
    "lr = LogisticRegression(random_state=42)\n",
    "lr.fit(X_train_balanced, y_train_balanced)\n",
    "y_pred_lr = lr.predict(X_test)\n",
    "models['Logistic Regression'] = lr\n",
    "results['Logistic Regression'] = classification_report(y_test, y_pred_lr, output_dict=True)\n",
    "\n",
    "# 2. Random Forest\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "rf.fit(X_train_balanced, y_train_balanced)\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "models['Random Forest'] = rf\n",
    "results['Random Forest'] = classification_report(y_test, y_pred_rf, output_dict=True)\n",
    "\n",
    "# 3. Gradient Boosting - XGBoost\n",
    "xgb = XGBClassifier(random_state=42)\n",
    "xgb.fit(X_train_balanced, y_train_balanced)\n",
    "y_pred_xgb = xgb.predict(X_test)\n",
    "models['XGBoost'] = xgb\n",
    "results['XGBoost'] = classification_report(y_test, y_pred_xgb, output_dict=True)\n",
    "\n",
    "# 4. Support Vector Machine (SVM)\n",
    "svm = SVC(random_state=42)\n",
    "svm.fit(X_train_balanced, y_train_balanced)\n",
    "y_pred_svm = svm.predict(X_test)\n",
    "models['SVM'] = svm\n",
    "results['SVM'] = classification_report(y_test, y_pred_svm, output_dict=True)\n",
    "\n",
    "# 5. Neural Network (MLP)\n",
    "mlp = MLPClassifier(random_state=42, max_iter=300)\n",
    "mlp.fit(X_train_balanced, y_train_balanced)\n",
    "y_pred_mlp = mlp.predict(X_test)\n",
    "models['Neural Network (MLP)'] = mlp\n",
    "results['Neural Network (MLP)'] = classification_report(y_test, y_pred_mlp, output_dict=True)\n",
    "\n",
    "# 6. K-Nearest Neighbors (KNN)\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(X_train_balanced, y_train_balanced)\n",
    "y_pred_knn = knn.predict(X_test)\n",
    "models['KNN'] = knn\n",
    "results['KNN'] = classification_report(y_test, y_pred_knn, output_dict=True)\n",
    "\n",
    "# Output the classification reports for all models\n",
    "for model_name, model in models.items():\n",
    "    print(f\"\\n{model_name} Results:\")\n",
    "    \n",
    "    # Predicting on the test set\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Printing the classification report\n",
    "    print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ee7893c2-b5c0-4514-a09f-e0b0d689ddac",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----------------------+------------+-------------+----------+------------+\n",
      "|    | Model                |   Accuracy |   Precision |   Recall |   F1 Score |\n",
      "+====+======================+============+=============+==========+============+\n",
      "|  0 | Logistic Regression  |   0.618812 |    0.568754 | 0.553808 |   0.52327  |\n",
      "+----+----------------------+------------+-------------+----------+------------+\n",
      "|  1 | Random Forest        |   0.584158 |    0.513686 | 0.518681 |   0.487949 |\n",
      "+----+----------------------+------------+-------------+----------+------------+\n",
      "|  2 | XGBoost              |   0.569307 |    0.509758 | 0.51688  |   0.508811 |\n",
      "+----+----------------------+------------+-------------+----------+------------+\n",
      "|  3 | SVM                  |   0.584158 |    0.520474 | 0.508046 |   0.458301 |\n",
      "+----+----------------------+------------+-------------+----------+------------+\n",
      "|  4 | Neural Network (MLP) |   0.549505 |    0.496035 | 0.49751  |   0.489042 |\n",
      "+----+----------------------+------------+-------------+----------+------------+\n",
      "|  5 | KNN                  |   0.514851 |    0.472222 | 0.478739 |   0.472069 |\n",
      "+----+----------------------+------------+-------------+----------+------------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\GG\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from tabulate import tabulate  # For creating a table\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Fit models, collect metrics\n",
    "metrics = []\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    report = classification_report(y_test, y_pred, output_dict=True)\n",
    "    \n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = report['macro avg']['precision']\n",
    "    recall = report['macro avg']['recall']\n",
    "    f1_score = report['macro avg']['f1-score']\n",
    "    \n",
    "    metrics.append([name, accuracy, precision, recall, f1_score])\n",
    "\n",
    "# Convert metrics to DataFrame\n",
    "metrics_df = pd.DataFrame(metrics, columns=['Model', 'Accuracy', 'Precision', 'Recall', 'F1 Score'])\n",
    "\n",
    "# Print the table\n",
    "print(tabulate(metrics_df, headers='keys', tablefmt='grid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92f757d7-93f0-4d15-8647-3b382eed4636",
   "metadata": {},
   "source": [
    "# Tuned Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c1bc6024-fc66-42ef-9971-e99875e0b7df",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\GG\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\GG\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\GG\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\GG\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\GG\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\GG\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\GG\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\GG\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\GG\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\GG\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\GG\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\GG\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\GG\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\GG\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\GG\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\GG\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\GG\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\GG\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\GG\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\GG\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\GG\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\GG\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\GG\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\GG\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\GG\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\GG\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\GG\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\GG\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\GG\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\GG\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\GG\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\GG\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\GG\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\GG\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define parameter grids for each model\n",
    "param_grids = {\n",
    "    'Logistic Regression': {\n",
    "        'C': [0.01, 0.1, 1, 10]\n",
    "    },\n",
    "    'Random Forest': {\n",
    "        'n_estimators': [100, 200, 300],\n",
    "        'max_depth': [None, 10, 20, 30],\n",
    "        'min_samples_split': [2, 5, 10]\n",
    "    },\n",
    "    'XGBoost': {\n",
    "        'learning_rate': [0.01, 0.1, 0.2],\n",
    "        'n_estimators': [100, 200, 300],\n",
    "        'max_depth': [3, 6, 9]\n",
    "    },\n",
    "    'SVM': {\n",
    "        'C': [0.01, 0.1, 1, 10],\n",
    "        'kernel': ['linear', 'rbf']\n",
    "    },\n",
    "    'Neural Networks': {\n",
    "        'hidden_layer_sizes': [(50,), (100,), (50, 50)],\n",
    "        'activation': ['relu', 'tanh'],\n",
    "        'learning_rate_init': [0.001, 0.01]\n",
    "    },\n",
    "    'KNN': {\n",
    "        'n_neighbors': [3, 5, 7],\n",
    "        'metric': ['euclidean', 'manhattan']\n",
    "    }\n",
    "}\n",
    "\n",
    "# Create tuned models dictionary\n",
    "tuned_models = {}\n",
    "\n",
    "# Logistic Regression\n",
    "log_reg = LogisticRegression(max_iter=1000)\n",
    "grid_log_reg = GridSearchCV(log_reg, param_grids['Logistic Regression'], cv=5)\n",
    "grid_log_reg.fit(X_train_balanced, y_train_balanced)\n",
    "tuned_models['Logistic Regression'] = grid_log_reg.best_estimator_\n",
    "\n",
    "# Random Forest\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "grid_rf = GridSearchCV(rf, param_grids['Random Forest'], cv=5)\n",
    "grid_rf.fit(X_train_balanced, y_train_balanced)\n",
    "tuned_models['Random Forest'] = grid_rf.best_estimator_\n",
    "\n",
    "# XGBoost\n",
    "xgb = XGBClassifier(random_state=42)\n",
    "grid_xgb = GridSearchCV(xgb, param_grids['XGBoost'], cv=5)\n",
    "grid_xgb.fit(X_train_balanced, y_train_balanced)\n",
    "tuned_models['XGBoost'] = grid_xgb.best_estimator_\n",
    "\n",
    "# SVM\n",
    "svm = SVC()\n",
    "grid_svm = GridSearchCV(svm, param_grids['SVM'], cv=5)\n",
    "grid_svm.fit(X_train_balanced, y_train_balanced)\n",
    "tuned_models['SVM'] = grid_svm.best_estimator_\n",
    "\n",
    "# Neural Network (MLP)\n",
    "mlp = MLPClassifier(max_iter=300)\n",
    "grid_mlp = GridSearchCV(mlp, param_grids['Neural Networks'], cv=5)\n",
    "grid_mlp.fit(X_train_balanced, y_train_balanced)\n",
    "tuned_models['Neural Networks'] = grid_mlp.best_estimator_\n",
    "\n",
    "# KNN\n",
    "knn = KNeighborsClassifier()\n",
    "grid_knn = GridSearchCV(knn, param_grids['KNN'], cv=5)\n",
    "grid_knn.fit(X_train_balanced, y_train_balanced)\n",
    "tuned_models['KNN'] = grid_knn.best_estimator_\n",
    "\n",
    "# Now you have the best tuned models in `tuned_models`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9da267b4-41e3-433a-a437-3950a617e00e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Initialize dictionaries to store accuracy results\n",
    "base_results = {}\n",
    "tuned_results = {}\n",
    "\n",
    "# Extract accuracy from the classification report for base models\n",
    "for model_name, model in models.items():\n",
    "    y_pred = model.predict(X_test)\n",
    "    report = classification_report(y_test, y_pred, output_dict=True)\n",
    "    base_results[model_name] = report['accuracy']\n",
    "\n",
    "# Assuming 'tuned_models' is another dictionary with tuned models\n",
    "# For simplicity, let's say tuned_models exist similar to base models\n",
    "for model_name, model in tuned_models.items():  # Add your tuned models here\n",
    "    y_pred = model.predict(X_test)\n",
    "    report = classification_report(y_test, y_pred, output_dict=True)\n",
    "    tuned_results[model_name] = report['accuracy']\n",
    "\n",
    "# Plot the results\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(base_results.keys(), base_results.values(), alpha=0.6, label='Base Models')\n",
    "plt.bar(tuned_results.keys(), tuned_results.values(), alpha=0.6, label='Tuned Models')\n",
    "plt.xlabel('Model')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Model Comparison: Base vs Tuned')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "259c9023-5730-48ae-b792-4320d75fcf82",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----------------------+------------+-------------+----------+------------+\n",
      "|    | Model                |   Accuracy |   Precision |   Recall |   F1 Score |\n",
      "+====+======================+============+=============+==========+============+\n",
      "|  0 | Logistic Regression  |   0.618812 |    0.568754 | 0.553808 |   0.52327  |\n",
      "+----+----------------------+------------+-------------+----------+------------+\n",
      "|  1 | Random Forest        |   0.584158 |    0.513686 | 0.518681 |   0.487949 |\n",
      "+----+----------------------+------------+-------------+----------+------------+\n",
      "|  2 | XGBoost              |   0.569307 |    0.509758 | 0.51688  |   0.508811 |\n",
      "+----+----------------------+------------+-------------+----------+------------+\n",
      "|  3 | SVM                  |   0.584158 |    0.520474 | 0.508046 |   0.458301 |\n",
      "+----+----------------------+------------+-------------+----------+------------+\n",
      "|  4 | Neural Network (MLP) |   0.549505 |    0.496035 | 0.49751  |   0.489042 |\n",
      "+----+----------------------+------------+-------------+----------+------------+\n",
      "|  5 | KNN                  |   0.514851 |    0.472222 | 0.478739 |   0.472069 |\n",
      "+----+----------------------+------------+-------------+----------+------------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\GG\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from tabulate import tabulate  # For creating a table\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Fit models, collect metrics\n",
    "metrics = []\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    report = classification_report(y_test, y_pred, output_dict=True)\n",
    "    \n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = report['macro avg']['precision']\n",
    "    recall = report['macro avg']['recall']\n",
    "    f1_score = report['macro avg']['f1-score']\n",
    "    \n",
    "    metrics.append([name, accuracy, precision, recall, f1_score])\n",
    "\n",
    "# Convert metrics to DataFrame\n",
    "metrics_df = pd.DataFrame(metrics, columns=['Model', 'Accuracy', 'Precision', 'Recall', 'F1 Score'])\n",
    "\n",
    "# Print the table\n",
    "print(tabulate(metrics_df, headers='keys', tablefmt='grid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ab492030-dc0a-49bc-9f1f-7e0f60086ed6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train_balanced: (4353, 12)\n",
      "First few rows of X_train_balanced:\n",
      "[[-0.49571234 -0.88242013 -1.03477926 -0.40817436  0.72598046  0.60173919\n",
      "   0.0896455  -0.61942101  1.12657454  1.75621697 -0.23010797 -0.25470313]\n",
      " [-0.49571234  1.34230111 -0.65433878  2.56702174  1.30987604  1.44321823\n",
      "  -0.55990707  1.21430149 -0.48039966  0.97599836  3.96643734 -0.25470313]\n",
      " [-0.67209676 -0.07343059  0.10654219  0.44188167 -1.02570629  0.60173919\n",
      "   0.73919806 -0.98616551 -0.48039966  0.19577976 -0.23010797 -0.25470313]\n",
      " [ 0.915363   -0.27567797  1.24786364  0.44188167  0.72598046  1.72371124\n",
      "   0.0896455  -0.61942101  0.32308744  1.75621697 -0.23010797 -0.25470313]\n",
      " [-0.84848118 -0.47792536 -1.41521974  0.01685365  0.43403267  0.32124618\n",
      "  -1.53423592 -0.98616551  0.32308744  0.97599836 -0.23010797 -0.25470313]]\n"
     ]
    }
   ],
   "source": [
    "# Print the shape of the balanced training data\n",
    "print(f\"Shape of X_train_balanced: {X_train_balanced.shape}\")\n",
    "\n",
    "# If X_train_balanced is a numpy array, use slicing\n",
    "print(\"First few rows of X_train_balanced:\")\n",
    "print(X_train_balanced[:5])  # Adjust the number of rows as needed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffcc4db6-bbd3-49d4-9b2e-4c704387dea5",
   "metadata": {},
   "source": [
    "# Checking Learning Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e4b7422-438a-4fe0-89ff-66b9f9d072bc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from sklearn.model_selection import GridSearchCV, learning_curve\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from xgboost import XGBClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Define parameter grids for GridSearchCV\n",
    "param_grids = {\n",
    "    'Logistic Regression': {\n",
    "        'C': [0.1, 1, 10],  # Regularization parameter\n",
    "        'solver': ['lbfgs', 'liblinear']  # Optimization algorithm\n",
    "    },\n",
    "    'Random Forest': {\n",
    "        'n_estimators': [100, 200],  # Number of trees in the forest\n",
    "        'max_depth': [None, 10, 20],  # Maximum depth of the tree\n",
    "        'min_samples_split': [2, 5, 10]  # Minimum number of samples required to split an internal node\n",
    "    },\n",
    "    'XGBoost': {\n",
    "        'n_estimators': [100, 200],  # Number of boosting rounds\n",
    "        'max_depth': [3, 5, 7],  # Maximum depth of the trees\n",
    "        'learning_rate': [0.01, 0.1]  # Step size shrinkage\n",
    "    },\n",
    "    'SVM': {\n",
    "        'C': [0.1, 1, 10],  # Regularization parameter\n",
    "        'kernel': ['linear', 'rbf'],  # Kernel type\n",
    "        'gamma': ['scale', 'auto']  # Kernel coefficient for 'rbf'\n",
    "    },\n",
    "    'Neural Networks': {\n",
    "        'hidden_layer_sizes': [(50,), (100,), (50, 50)],  # Size of hidden layers\n",
    "        'activation': ['relu', 'tanh'],  # Activation function\n",
    "        'solver': ['adam', 'sgd']  # Optimization algorithm\n",
    "    },\n",
    "    'KNN': {\n",
    "        'n_neighbors': [3, 5, 7],  # Number of neighbors to use\n",
    "        'weights': ['uniform', 'distance']  # Weight function used in prediction\n",
    "    }\n",
    "}\n",
    "\n",
    "# Define function to plot learning curves\n",
    "def plot_learning_curve(model, X, y, title):\n",
    "    train_sizes, train_scores, validation_scores = learning_curve(\n",
    "        model, X, y, cv=5, scoring='accuracy', n_jobs=-1, \n",
    "        train_sizes=np.linspace(0.1, 1.0, 10)\n",
    "    )\n",
    "    \n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    validation_scores_mean = np.mean(validation_scores, axis=1)\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Training examples\")\n",
    "    plt.ylabel(\"Score\")\n",
    "    plt.grid()\n",
    "\n",
    "    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\", label=\"Training score\")\n",
    "    plt.plot(train_sizes, validation_scores_mean, 'o-', color=\"g\", label=\"Validation score\")\n",
    "    \n",
    "    plt.legend(loc=\"best\")\n",
    "    plt.show()\n",
    "\n",
    "# Create tuned models dictionary\n",
    "tuned_models = {}\n",
    "\n",
    "# Measure and log time for model tuning\n",
    "def time_model_tuning(model_name, model, param_grid, X_train, y_train):\n",
    "    start_time = time.time()\n",
    "    grid_search = GridSearchCV(model, param_grid, cv=5)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    end_time = time.time()\n",
    "    duration = end_time - start_time\n",
    "    print(f\"{model_name} tuning took {duration:.2f} seconds\")\n",
    "    return grid_search.best_estimator_\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train_balanced_scaled = scaler.fit_transform(X_train_balanced)\n",
    "\n",
    "\n",
    "# Logistic Regression\n",
    "log_reg = LogisticRegression(max_iter=1000)\n",
    "grid_log_reg = GridSearchCV(log_reg, param_grids['Logistic Regression'], cv=5)\n",
    "grid_log_reg.fit(X_train_balanced, y_train_balanced)\n",
    "tuned_models['Logistic Regression'] = grid_log_reg.best_estimator_\n",
    "\n",
    "# Random Forest\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "grid_rf = GridSearchCV(rf, param_grids['Random Forest'], cv=5)\n",
    "grid_rf.fit(X_train_balanced, y_train_balanced)\n",
    "tuned_models['Random Forest'] = grid_rf.best_estimator_\n",
    "\n",
    "# XGBoost\n",
    "xgb = XGBClassifier(random_state=42)\n",
    "grid_xgb = GridSearchCV(xgb, param_grids['XGBoost'], cv=5)\n",
    "grid_xgb.fit(X_train_balanced, y_train_balanced)\n",
    "tuned_models['XGBoost'] = grid_xgb.best_estimator_\n",
    "\n",
    "# SVM\n",
    "svm = SVC()\n",
    "grid_svm = GridSearchCV(svm, param_grids['SVM'], cv=5)\n",
    "grid_svm.fit(X_train_balanced, y_train_balanced)\n",
    "tuned_models['SVM'] = grid_svm.best_estimator_\n",
    "\n",
    "# Neural Network (MLP)\n",
    "mlp = MLPClassifier(max_iter=300)\n",
    "grid_mlp = GridSearchCV(mlp, param_grids['Neural Networks'], cv=5)\n",
    "grid_mlp.fit(X_train_balanced, y_train_balanced)\n",
    "tuned_models['Neural Networks'] = grid_mlp.best_estimator_\n",
    "\n",
    "# KNN\n",
    "knn = KNeighborsClassifier()\n",
    "grid_knn = GridSearchCV(knn, param_grids['KNN'], cv=5)\n",
    "grid_knn.fit(X_train_balanced, y_train_balanced)\n",
    "tuned_models['KNN'] = grid_knn.best_estimator_\n",
    "\n",
    "# Plot learning curves for each model\n",
    "for name, model in tuned_models.items():\n",
    "    plot_learning_curve(model, X_train_balanced, y_train_balanced, title=f'Learning Curve ({name})')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "950bc17a-cc94-486b-af42-c30505996f12",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from sklearn.model_selection import GridSearchCV, learning_curve\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from xgboost import XGBClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Define parameter grids for GridSearchCV\n",
    "param_grids = {\n",
    "    'Logistic Regression': {\n",
    "        'C': [0.1, 1, 10],\n",
    "        'solver': ['lbfgs', 'liblinear']\n",
    "    },\n",
    "    'Random Forest': {\n",
    "        'n_estimators': [100, 200],\n",
    "        'max_depth': [None, 10, 20],\n",
    "        'min_samples_split': [2, 5, 10]\n",
    "    },\n",
    "    'XGBoost': {\n",
    "        'n_estimators': [100, 200],\n",
    "        'max_depth': [3, 5, 7],\n",
    "        'learning_rate': [0.01, 0.1]\n",
    "    },\n",
    "    'SVM': {\n",
    "        'C': [0.1, 1, 10],\n",
    "        'kernel': ['linear', 'rbf'],\n",
    "        'gamma': ['scale', 'auto']\n",
    "    },\n",
    "    'Neural Networks': {\n",
    "        'hidden_layer_sizes': [(50,), (100,), (50, 50)],\n",
    "        'activation': ['relu', 'tanh'],\n",
    "        'solver': ['adam', 'sgd']\n",
    "    },\n",
    "    'KNN': {\n",
    "        'n_neighbors': [3, 5, 7],\n",
    "        'weights': ['uniform', 'distance']\n",
    "    }\n",
    "}\n",
    "\n",
    "# Define function to plot learning curves and print the learning curve table\n",
    "def plot_learning_curve(model, X, y, title):\n",
    "    train_sizes, train_scores, validation_scores = learning_curve(\n",
    "        model, X, y, cv=5, scoring='accuracy', n_jobs=-1, \n",
    "        train_sizes=np.linspace(0.1, 1.0, 10)\n",
    "    )\n",
    "    \n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    validation_scores_mean = np.mean(validation_scores, axis=1)\n",
    "    \n",
    "    # Plotting the learning curve\n",
    "    plt.figure()\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Training examples\")\n",
    "    plt.ylabel(\"Score\")\n",
    "    plt.grid()\n",
    "\n",
    "    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\", label=\"Training score\")\n",
    "    plt.plot(train_sizes, validation_scores_mean, 'o-', color=\"g\", label=\"Validation score\")\n",
    "    \n",
    "    plt.legend(loc=\"best\")\n",
    "    plt.show()\n",
    "    \n",
    "    # Printing the learning curve table\n",
    "    print(f\"\\nLearning Curve for {title}:\")\n",
    "    learning_curve_data = pd.DataFrame({\n",
    "        \"Training Size\": train_sizes,\n",
    "        \"Training Score\": train_scores_mean,\n",
    "        \"Validation Score\": validation_scores_mean\n",
    "    })\n",
    "    print(learning_curve_data)\n",
    "\n",
    "# Create tuned models dictionary\n",
    "tuned_models = {}\n",
    "\n",
    "# Measure and log time for model tuning\n",
    "def time_model_tuning(model_name, model, param_grid, X_train, y_train):\n",
    "    start_time = time.time()\n",
    "    grid_search = GridSearchCV(model, param_grid, cv=5)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    end_time = time.time()\n",
    "    duration = end_time - start_time\n",
    "    print(f\"{model_name} tuning took {duration:.2f} seconds\")\n",
    "    return grid_search.best_estimator_\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train_balanced_scaled = scaler.fit_transform(X_train_balanced)\n",
    "\n",
    "# Logistic Regression\n",
    "log_reg = LogisticRegression(max_iter=1000)\n",
    "grid_log_reg = GridSearchCV(log_reg, param_grids['Logistic Regression'], cv=5)\n",
    "grid_log_reg.fit(X_train_balanced, y_train_balanced)\n",
    "tuned_models['Logistic Regression'] = grid_log_reg.best_estimator_\n",
    "\n",
    "# Random Forest\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "grid_rf = GridSearchCV(rf, param_grids['Random Forest'], cv=5)\n",
    "grid_rf.fit(X_train_balanced, y_train_balanced)\n",
    "tuned_models['Random Forest'] = grid_rf.best_estimator_\n",
    "\n",
    "# XGBoost\n",
    "xgb = XGBClassifier(random_state=42)\n",
    "grid_xgb = GridSearchCV(xgb, param_grids['XGBoost'], cv=5)\n",
    "grid_xgb.fit(X_train_balanced, y_train_balanced)\n",
    "tuned_models['XGBoost'] = grid_xgb.best_estimator_\n",
    "\n",
    "# SVM\n",
    "svm = SVC()\n",
    "grid_svm = GridSearchCV(svm, param_grids['SVM'], cv=5)\n",
    "grid_svm.fit(X_train_balanced, y_train_balanced)\n",
    "tuned_models['SVM'] = grid_svm.best_estimator_\n",
    "\n",
    "# Neural Network (MLP)\n",
    "mlp = MLPClassifier(max_iter=300)\n",
    "grid_mlp = GridSearchCV(mlp, param_grids['Neural Networks'], cv=5)\n",
    "grid_mlp.fit(X_train_balanced, y_train_balanced)\n",
    "tuned_models['Neural Networks'] = grid_mlp.best_estimator_\n",
    "\n",
    "# KNN\n",
    "knn = KNeighborsClassifier()\n",
    "grid_knn = GridSearchCV(knn, param_grids['KNN'], cv=5)\n",
    "grid_knn.fit(X_train_balanced, y_train_balanced)\n",
    "tuned_models['KNN'] = grid_knn.best_estimator_\n",
    "\n",
    "# Plot learning curves and print learning curve values for each model\n",
    "for name, model in tuned_models.items():\n",
    "    plot_learning_curve(model, X_train_balanced, y_train_balanced, title=f'Learning Curve ({name})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "155c0a50-d49b-4afc-a165-f30dfe0ba93b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define function to plot learning curves and print the learning curve table\n",
    "def plot_learning_curve(model, X, y, title):\n",
    "    train_sizes, train_scores, validation_scores = learning_curve(\n",
    "        model, X, y, cv=5, scoring='accuracy', n_jobs=-1, \n",
    "        train_sizes=np.linspace(0.1, 1.0, 10)\n",
    "    )\n",
    "    \n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    validation_scores_mean = np.mean(validation_scores, axis=1)\n",
    "    \n",
    "    # Plotting the learning curve\n",
    "    plt.figure()\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Training examples\")\n",
    "    plt.ylabel(\"Score\")\n",
    "    plt.grid()\n",
    "\n",
    "    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\", label=\"Training score\")\n",
    "    plt.plot(train_sizes, validation_scores_mean, 'o-', color=\"g\", label=\"Validation score\")\n",
    "    \n",
    "    plt.legend(loc=\"best\")\n",
    "    plt.show()\n",
    "    \n",
    "    # Added section: Printing the learning curve table\n",
    "    print(f\"\\nLearning Curve for {title}:\")\n",
    "    learning_curve_data = pd.DataFrame({\n",
    "        \"Training Size\": train_sizes,\n",
    "        \"Training Score\": train_scores_mean,\n",
    "        \"Validation Score\": validation_scores_mean\n",
    "    })\n",
    "    print(learning_curve_data)  # This will print the table of learning curve values\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
